{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOorBu/6Syt1wjlQAFRBwi5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judith182/BIOESTAD-STICA/blob/main/Prostatectom%C3%ADa_Regresi%C3%B3n_Ridge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjE3vAL7_Oqb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = pd.read_csv(\"prostate_dataset.txt\", sep='\\t')\n",
        "data = data.drop(['col'], axis=1)\n",
        "\n",
        "data\n",
        "# The data were collected on n=97 men before radical prostatectomy,\n",
        "# which a major surgical operation that removes the entire prostate\n",
        "# gland along with some surrounding tissue.\n",
        "\n",
        "# lcavol  = log cancer volumne, measure in milliliters (cc). The area\n",
        "#           of cancer was measure from digitized images and multiplied\n",
        "#           by a thickness to produce a volume.\n",
        "# lweight = log prostate weight\n",
        "# age     = age\n",
        "# lbph    = log of the amount of benign prostatic hyperplasia, a\n",
        "#           noncancerous enlargement of the prostate gland, as an area in\n",
        "#           a digitized image and reported in cm2.\n",
        "# svi     = seminal vesicle invasion, a 0/1 indicator of whether prostate\n",
        "#           cancer cells hae invaded the vesicle.\n",
        "# lcp     = log capsular penetration, which represents the level of\n",
        "#           extension of cancer into the capsule (the fibrous tissue\n",
        "#           which acts as an outer lining of the prostate gland).\n",
        "#           Measure as the linear extent of penetration, in cm.\n",
        "# gleason = Gleason score, a measure of the degree of aggressiveness of\n",
        "#           the tumor. The Gleason grading system assigns a grade\n",
        "#           to each of the two largest areas of cancer in the tissue\n",
        "#           samples with 1 being the least aggressive and 5 the most\n",
        "#           aggressive; the two grades are then added together to produce\n",
        "#           the Gleason score.\n",
        "# pgg45   = percent of Gleason score 4 or 5.\n",
        "# lpsa    = log prostate specific antigen\n",
        "\n",
        "# See Hastie et al (2008) The Elements of Stat. Learning (pp. 49)\n",
        "# and Wakefiled (2013) (pp. 5)\n",
        "\n",
        "# PSA is a concentration and is measure in ng/ml.\n",
        "# In Stamey et al (1989), PSA was proposed as a preoperative marker\n",
        "# to predict  the clinical stage of cancer.\n",
        "# PSA is a protein produced by the cells of the prostate gland.\n",
        "# PSA is present in small quantities in the serum of men with healthy\n",
        "# prostates, but is often elevated in the presence of prostate cancer\n",
        "# and in other prostate disorders. A blood test to measure PSA is\n",
        "# considered the most effective test currently available for the early\n",
        "# detection of prostate cancer, but this effectiveness has also\n",
        "# been questioned. Rising levels of PSA over time are associated\n",
        "# with both localized and metastatic prostate cancer.\n",
        "\n",
        "#################################################\n",
        "##                                             ##\n",
        "## Creating the training and testing data sets ##\n",
        "##                                             ##\n",
        "#################################################\n",
        "\n",
        "train_data = data[data['train'] == 'T']\n",
        "test_data = data[data['train'] == 'F']\n",
        "\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "data = data.drop(['train'], axis=1)\n",
        "train_data = train_data.drop(['train'], axis=1)\n",
        "test_data = test_data.drop(['train'], axis=1)\n",
        "\n",
        "X_train = train_data.drop('lpsa', axis=1)\n",
        "y_train = train_data['lpsa']\n",
        "\n",
        "X_test = test_data.drop('lpsa', axis=1)\n",
        "y_test = test_data['lpsa']\n",
        "\n",
        "###############################\n",
        "##                           ##\n",
        "## Exploring multicolinearty ##\n",
        "##                           ##\n",
        "###############################\n",
        "\n",
        "corr_matrix = train_data.corr()\n",
        "plt.figure(figsize=(10,7.5))\n",
        "sns.heatmap(corr_matrix, cmap='Purples')\n",
        "\n",
        "sns.pairplot(train_data, kind=\"reg\", corner = True,\n",
        "    plot_kws={'line_kws':{'color':'orange'}, 'scatter_kws': {'color': 'rebeccapurple'}},\n",
        "    diag_kws={'color': 'rebeccapurple'})\n",
        "\n",
        "# Let's see the eigenvalues of the matrix XTX\n",
        "u, d, vh = np.linalg.svd(X_train, full_matrices=True)\n",
        "np.round(d**2,2)\n",
        "\n",
        "n_lambdas = 200\n",
        "lambdas = np.logspace(0, 5, n_lambdas)\n",
        "df_l = []\n",
        "coefs = []\n",
        "\n",
        "for l in lambdas:\n",
        "    df_l.append(sum(d**2/(d**2+l)))\n",
        "    ridge = Ridge(alpha=l, fit_intercept=True).fit(X_train, y_train)\n",
        "    coefs.append(ridge.coef_)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7.5))\n",
        "ax.plot(df_l, coefs)\n",
        "ax.set_xlabel('df')\n",
        "ax.set_ylabel('betas')\n",
        "ax.set_title('Ridge coefficients as a function of effective degrees of freedom')\n",
        "ax.grid(True)\n",
        "plt.legend(X_train.columns)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7.5))\n",
        "ax.plot(lambdas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlim(ax.get_xlim()[::-1])  # decreasing time\n",
        "ax.set_xlabel('lambda')\n",
        "ax.set_ylabel('betas')\n",
        "ax.set_title('Ridge coefficients as a function of the regularization')\n",
        "ax.grid(True)\n",
        "plt.legend(X_train.columns)\n",
        "\n",
        "n_repeats = 1\n",
        "n_splits = 67\n",
        "kf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=None)\n",
        "\n",
        "MSE_per_lambda_and_K_fold = np.zeros((n_repeats*n_splits, n_lambdas))\n",
        "\n",
        "for i, index in enumerate(kf.split(X_train)):\n",
        "    train_index, valid_index = index\n",
        "    X_Kfold, X_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
        "    y_Kfold, y_valid = y_train[train_index], y_train[valid_index]\n",
        "\n",
        "    for j, l in enumerate(lambdas):\n",
        "        ridge = Ridge(alpha=l).fit(X_Kfold, y_Kfold)\n",
        "        hat_y_valid = ridge.predict(X_valid)\n",
        "        MSE_per_lambda_and_K_fold[i,j] = mean_squared_error(y_valid, hat_y_valid)\n",
        "\n",
        "mean_MSE = MSE_per_lambda_and_K_fold.mean(axis=0)\n",
        "\n",
        "plt.figure(figsize=(10,7.5))\n",
        "plt.plot(df_l, mean_MSE)\n",
        "\n",
        "hat_lambda = lambdas[np.argmin(mean_MSE)]\n",
        "hat_lambda\n",
        "sum(d**2/(d**2+hat_lambda))\n",
        "mean_MSE.min()\n",
        "\n",
        "model_ridge = Ridge(alpha=hat_lambda).fit(X_train,y_train)\n",
        "model_ridge.coef_\n",
        "model_ridge.intercept_\n",
        "\n",
        "clf = RidgeCV(alphas=lambdas).fit(X_train, y_train)\n",
        "clf.alpha_\n",
        "clf.best_score_\n",
        "clf.coef_\n",
        "clf.intercept_\n",
        "\n",
        "mean_squared_error(y_test, clf.predict(X_test))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7.5))\n",
        "ax.plot(df_l, coefs)\n",
        "ax.set_xlabel('df')\n",
        "ax.set_ylabel('betas')\n",
        "ax.set_title('Ridge coefficients as a function of effective degrees of freedom')\n",
        "ax.grid(True)\n",
        "plt.axvline(sum(d**2/(d**2+hat_lambda)), c='r', ls='--')\n",
        "plt.legend(X_train.columns)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7.5))\n",
        "ax.plot(lambdas, coefs)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlim(ax.get_xlim()[::-1])  # decreasing time\n",
        "ax.set_xlabel('lambda')\n",
        "ax.set_ylabel('betas')\n",
        "ax.set_title('Ridge coefficients as a function of the regularization')\n",
        "ax.grid(True)\n",
        "plt.axvline(clf.alpha_, c='r', ls='--')\n",
        "plt.legend(X_train.columns)\n",
        "\n",
        "\n",
        "\n",
        "####\n"
      ]
    }
  ]
}